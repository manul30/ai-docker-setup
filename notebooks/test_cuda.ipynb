{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9845c740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU matmul time: 0.0554 seconds\n",
      "GPU matmul time: 0.0053 seconds\n",
      "XLA-optimized GPU matmul time: 0.0124 seconds\n",
      "XLA-optimized CPU matmul time: 0.0633 seconds\n",
      "\n",
      "Summary:\n",
      "CPU: 0.0554 seconds\n",
      "GPU: 0.0053 seconds\n",
      "XLA_GPU: 0.0124 seconds\n",
      "XLA_CPU: 0.0633 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compare all timings in one place\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size = 2048\n",
    "results = {}\n",
    "\n",
    "# CPU baseline\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal((size, size))\n",
    "    b = tf.random.normal((size, size))\n",
    "    start = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    _ = c.numpy()\n",
    "    cpu_time = time.time() - start\n",
    "    results['CPU'] = cpu_time\n",
    "    print(f\"CPU matmul time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# GPU baseline\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.random.normal((size, size))\n",
    "        b = tf.random.normal((size, size))\n",
    "        start = time.time()\n",
    "        c = tf.matmul(a, b)\n",
    "        _ = c.numpy()\n",
    "        gpu_time = time.time() - start\n",
    "        results['GPU'] = gpu_time\n",
    "        print(f\"GPU matmul time: {gpu_time:.4f} seconds\")\n",
    "\n",
    "# XLA on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    @tf.function(jit_compile=True)\n",
    "    def xla_gpu(a, b):\n",
    "        return tf.matmul(a, b)\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.random.normal((size, size))\n",
    "        b = tf.random.normal((size, size))\n",
    "        start = time.time()\n",
    "        c = xla_gpu(a, b)\n",
    "        _ = c.numpy()\n",
    "        xla_gpu_time = time.time() - start\n",
    "        results['XLA_GPU'] = xla_gpu_time\n",
    "        print(f\"XLA-optimized GPU matmul time: {xla_gpu_time:.4f} seconds\")\n",
    "\n",
    "# XLA on CPU\n",
    "@tf.function(jit_compile=True)\n",
    "def xla_cpu(a, b):\n",
    "    return tf.matmul(a, b)\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal((size, size))\n",
    "    b = tf.random.normal((size, size))\n",
    "    start = time.time()\n",
    "    c = xla_cpu(a, b)\n",
    "    _ = c.numpy()\n",
    "    xla_cpu_time = time.time() - start\n",
    "    results['XLA_CPU'] = xla_cpu_time\n",
    "    print(f\"XLA-optimized CPU matmul time: {xla_cpu_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948a2d3",
   "metadata": {},
   "source": [
    "# Compilation Overhead and Repeated Benchmarking\n",
    "This cell will run each operation multiple times to show the effect of TensorFlow's graph/XLA compilation and warm-up. The first run may be slower due to compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e70f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU baseline:\n",
      "CPU run 1: 0.0171 seconds\n",
      "CPU run 2: 0.0167 seconds\n",
      "CPU run 3: 0.0145 seconds\n",
      "CPU run 4: 0.0134 seconds\n",
      "CPU run 5: 0.0110 seconds\n",
      "CPU avg: 0.0145 seconds\n",
      "\n",
      "GPU baseline:\n",
      "GPU run 1: 0.0030 seconds\n",
      "GPU run 2: 0.0019 seconds\n",
      "GPU run 3: 0.0020 seconds\n",
      "GPU run 4: 0.0017 seconds\n",
      "GPU run 5: 0.0017 seconds\n",
      "GPU avg: 0.0021 seconds\n",
      "\n",
      "XLA-optimized GPU:\n",
      "XLA_GPU run 1: 0.0226 seconds\n",
      "XLA_GPU run 2: 0.0020 seconds\n",
      "XLA_GPU run 3: 0.0039 seconds\n",
      "XLA_GPU run 4: 0.0017 seconds\n",
      "XLA_GPU run 5: 0.0016 seconds\n",
      "XLA_GPU avg: 0.0064 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size = 1024\n",
    "repeats = 5\n",
    "\n",
    "# Prepare data\n",
    "cpu_a = tf.random.normal((size, size))\n",
    "cpu_b = tf.random.normal((size, size))\n",
    "\n",
    "# Only create GPU tensors if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_a = tf.random.normal((size, size))\n",
    "    gpu_b = tf.random.normal((size, size))\n",
    "else:\n",
    "    gpu_a = gpu_b = None\n",
    "\n",
    "# Define XLA function\n",
    "@tf.function(jit_compile=True)\n",
    "def xla_matmul(a, b):\n",
    "    return tf.matmul(a, b)\n",
    "\n",
    "def bench(fn, a, b, device, label):\n",
    "    times = []\n",
    "    for i in range(repeats):\n",
    "        with tf.device(device):\n",
    "            start = time.time()\n",
    "            c = fn(a, b)\n",
    "            _ = c.numpy()\n",
    "            elapsed = time.time() - start\n",
    "            times.append(elapsed)\n",
    "            print(f\"{label} run {i+1}: {elapsed:.4f} seconds\")\n",
    "    print(f\"{label} avg: {np.mean(times):.4f} seconds\\n\")\n",
    "\n",
    "print(\"CPU baseline:\")\n",
    "bench(tf.matmul, cpu_a, cpu_b, '/CPU:0', 'CPU')\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU baseline:\")\n",
    "    bench(tf.matmul, gpu_a, gpu_b, '/GPU:0', 'GPU')\n",
    "    print(\"XLA-optimized GPU:\")\n",
    "    bench(xla_matmul, gpu_a, gpu_b, '/GPU:0', 'XLA_GPU')\n",
    "else:\n",
    "    print(\"XLA-optimized CPU:\")\n",
    "    bench(xla_matmul, cpu_a, cpu_b, '/CPU:0', 'XLA_CPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
