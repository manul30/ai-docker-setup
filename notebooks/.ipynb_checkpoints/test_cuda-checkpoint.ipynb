{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9845c740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768159840.824615     119 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1768159840.865719     119 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768159841.963600     119 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1768159842.836805     154 cuda_executor.cc:1767] Failed to determine cuDNN version (Note that this is expected if the application doesn't link the cuDNN plugin): INTERNAL: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\n",
      "W0000 00:00:1768159843.007910     119 gpu_device.cc:2365] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "I0000 00:00:1768159843.188036     119 service.cc:153] XLA service 0x559f7621b820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1768159843.188054     119 service.cc:161]   StreamExecutor [0]: Host, Default Version (Driver: 0.0.0; Runtime: 0.0.0; Toolkit: 0.0.0; DNN: 0.0.0)\n",
      "I0000 00:00:1768159843.195222     119 device_compiler.h:208] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU matmul time: 0.0782 seconds\n",
      "XLA-optimized CPU matmul time: 0.0878 seconds\n",
      "\n",
      "Summary:\n",
      "CPU: 0.0782 seconds\n",
      "XLA_CPU: 0.0878 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compare all timings in one place\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size = 2048\n",
    "results = {}\n",
    "\n",
    "# CPU baseline\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal((size, size))\n",
    "    b = tf.random.normal((size, size))\n",
    "    start = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    _ = c.numpy()\n",
    "    cpu_time = time.time() - start\n",
    "    results['CPU'] = cpu_time\n",
    "    print(f\"CPU matmul time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# GPU baseline\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.random.normal((size, size))\n",
    "        b = tf.random.normal((size, size))\n",
    "        start = time.time()\n",
    "        c = tf.matmul(a, b)\n",
    "        _ = c.numpy()\n",
    "        gpu_time = time.time() - start\n",
    "        results['GPU'] = gpu_time\n",
    "        print(f\"GPU matmul time: {gpu_time:.4f} seconds\")\n",
    "\n",
    "# XLA on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    @tf.function(jit_compile=True)\n",
    "    def xla_gpu(a, b):\n",
    "        return tf.matmul(a, b)\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.random.normal((size, size))\n",
    "        b = tf.random.normal((size, size))\n",
    "        start = time.time()\n",
    "        c = xla_gpu(a, b)\n",
    "        _ = c.numpy()\n",
    "        xla_gpu_time = time.time() - start\n",
    "        results['XLA_GPU'] = xla_gpu_time\n",
    "        print(f\"XLA-optimized GPU matmul time: {xla_gpu_time:.4f} seconds\")\n",
    "\n",
    "# XLA on CPU\n",
    "@tf.function(jit_compile=True)\n",
    "def xla_cpu(a, b):\n",
    "    return tf.matmul(a, b)\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal((size, size))\n",
    "    b = tf.random.normal((size, size))\n",
    "    start = time.time()\n",
    "    c = xla_cpu(a, b)\n",
    "    _ = c.numpy()\n",
    "    xla_cpu_time = time.time() - start\n",
    "    results['XLA_CPU'] = xla_cpu_time\n",
    "    print(f\"XLA-optimized CPU matmul time: {xla_cpu_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948a2d3",
   "metadata": {},
   "source": [
    "# Compilation Overhead and Repeated Benchmarking\n",
    "This cell will run each operation multiple times to show the effect of TensorFlow's graph/XLA compilation and warm-up. The first run may be slower due to compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e70f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU baseline:\n",
      "CPU run 1: 0.0156 seconds\n",
      "CPU run 2: 0.0178 seconds\n",
      "CPU run 3: 0.0124 seconds\n",
      "CPU run 4: 0.0101 seconds\n",
      "CPU run 5: 0.0110 seconds\n",
      "CPU avg: 0.0134 seconds\n",
      "\n",
      "XLA-optimized CPU:\n",
      "XLA_CPU run 1: 0.0276 seconds\n",
      "XLA_CPU run 2: 0.0062 seconds\n",
      "XLA_CPU run 3: 0.0054 seconds\n",
      "XLA_CPU run 4: 0.0048 seconds\n",
      "XLA_CPU run 5: 0.0054 seconds\n",
      "XLA_CPU avg: 0.0099 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size = 1024\n",
    "repeats = 5\n",
    "\n",
    "# Prepare data\n",
    "cpu_a = tf.random.normal((size, size))\n",
    "cpu_b = tf.random.normal((size, size))\n",
    "\n",
    "# Only create GPU tensors if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_a = tf.random.normal((size, size))\n",
    "    gpu_b = tf.random.normal((size, size))\n",
    "else:\n",
    "    gpu_a = gpu_b = None\n",
    "\n",
    "# Define XLA function\n",
    "@tf.function(jit_compile=True)\n",
    "def xla_matmul(a, b):\n",
    "    return tf.matmul(a, b)\n",
    "\n",
    "def bench(fn, a, b, device, label):\n",
    "    times = []\n",
    "    for i in range(repeats):\n",
    "        with tf.device(device):\n",
    "            start = time.time()\n",
    "            c = fn(a, b)\n",
    "            _ = c.numpy()\n",
    "            elapsed = time.time() - start\n",
    "            times.append(elapsed)\n",
    "            print(f\"{label} run {i+1}: {elapsed:.4f} seconds\")\n",
    "    print(f\"{label} avg: {np.mean(times):.4f} seconds\\n\")\n",
    "\n",
    "print(\"CPU baseline:\")\n",
    "bench(tf.matmul, cpu_a, cpu_b, '/CPU:0', 'CPU')\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU baseline:\")\n",
    "    bench(tf.matmul, gpu_a, gpu_b, '/GPU:0', 'GPU')\n",
    "    print(\"XLA-optimized GPU:\")\n",
    "    bench(xla_matmul, gpu_a, gpu_b, '/GPU:0', 'XLA_GPU')\n",
    "else:\n",
    "    print(\"XLA-optimized CPU:\")\n",
    "    bench(xla_matmul, cpu_a, cpu_b, '/CPU:0', 'XLA_CPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
